/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 *
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// RealtimeServerEventConversationItemInputAudioTranscriptionCompleted : This event is the output of audio transcription for user audio written to the user audio buffer. Transcription begins when the input audio buffer is committed by the client or server (when VAD is enabled). Transcription runs asynchronously with Response creation, so this event may come before or after the Response events.  Realtime API models accept audio natively, and thus input transcription is a separate process run on a separate ASR (Automatic Speech Recognition) model. The transcript may diverge somewhat from the model's interpretation, and should be treated as a rough guide.
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, bon::Builder)]
pub struct RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
    /// The unique ID of the server event.
    #[serde(rename = "event_id")]
    pub event_id: String,
    /// The event type, must be `conversation.item.input_audio_transcription.completed`.
    #[serde(rename = "type")]
    pub r#type: Type,
    /// The ID of the item containing the audio that is being transcribed.
    #[serde(rename = "item_id")]
    pub item_id: String,
    /// The index of the content part containing the audio.
    #[serde(rename = "content_index")]
    pub content_index: i32,
    /// The transcribed text.
    #[serde(rename = "transcript")]
    pub transcript: String,
    /// The log probabilities of the transcription.
    #[serde(rename = "logprobs", skip_serializing_if = "Option::is_none")]
    pub logprobs: Option<Vec<models::LogProbProperties>>,
    #[serde(rename = "usage")]
    pub usage:
        Box<models::RealtimeServerEventConversationItemInputAudioTranscriptionCompletedUsage>,
}

impl RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
    /// This event is the output of audio transcription for user audio written to the user audio buffer. Transcription begins when the input audio buffer is committed by the client or server (when VAD is enabled). Transcription runs asynchronously with Response creation, so this event may come before or after the Response events.  Realtime API models accept audio natively, and thus input transcription is a separate process run on a separate ASR (Automatic Speech Recognition) model. The transcript may diverge somewhat from the model's interpretation, and should be treated as a rough guide.
    pub fn new(
        event_id: String,
        r#type: Type,
        item_id: String,
        content_index: i32,
        transcript: String,
        usage: models::RealtimeServerEventConversationItemInputAudioTranscriptionCompletedUsage,
    ) -> RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
        RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
            event_id,
            r#type,
            item_id,
            content_index,
            transcript,
            logprobs: None,
            usage: Box::new(usage),
        }
    }
}
/// The event type, must be `conversation.item.input_audio_transcription.completed`.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Type {
    #[serde(rename = "conversation.item.input_audio_transcription.completed")]
    ConversationItemInputAudioTranscriptionCompleted,
}

impl Default for Type {
    fn default() -> Type {
        Self::ConversationItemInputAudioTranscriptionCompleted
    }
}
