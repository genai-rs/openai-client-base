/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 *
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize, bon::Builder)]
pub struct EvalRunPerModelUsageInner {
    /// The name of the model.
    #[serde(rename = "model_name")]
    pub model_name: String,
    /// The number of invocations.
    #[serde(rename = "invocation_count")]
    pub invocation_count: i32,
    /// The number of prompt tokens used.
    #[serde(rename = "prompt_tokens")]
    pub prompt_tokens: i32,
    /// The number of completion tokens generated.
    #[serde(rename = "completion_tokens")]
    pub completion_tokens: i32,
    /// The total number of tokens used.
    #[serde(rename = "total_tokens")]
    pub total_tokens: i32,
    /// The number of tokens retrieved from cache.
    #[serde(rename = "cached_tokens")]
    pub cached_tokens: i32,
}

impl EvalRunPerModelUsageInner {
    pub fn new(
        model_name: String,
        invocation_count: i32,
        prompt_tokens: i32,
        completion_tokens: i32,
        total_tokens: i32,
        cached_tokens: i32,
    ) -> EvalRunPerModelUsageInner {
        EvalRunPerModelUsageInner {
            model_name,
            invocation_count,
            prompt_tokens,
            completion_tokens,
            total_tokens,
            cached_tokens,
        }
    }
}
