/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 *
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize, bon::Builder)]
pub struct RealtimeConversationItemMessageUserContentInner {
    /// The content type (`input_text`, `input_audio`, or `input_image`).
    #[serde(rename = "type", skip_serializing_if = "Option::is_none")]
    pub r#type: Option<Type>,
    /// The text content (for `input_text`).
    #[serde(rename = "text", skip_serializing_if = "Option::is_none")]
    pub text: Option<String>,
    /// Base64-encoded audio bytes (for `input_audio`), these will be parsed as the format specified in the session input audio type configuration. This defaults to PCM 16-bit 24kHz mono if not specified.
    #[serde(rename = "audio", skip_serializing_if = "Option::is_none")]
    pub audio: Option<String>,
    /// Base64-encoded image bytes (for `input_image`) as a data URI. For example `data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...`. Supported formats are PNG and JPEG.
    #[serde(rename = "image_url", skip_serializing_if = "Option::is_none")]
    pub image_url: Option<String>,
    /// The detail level of the image (for `input_image`). `auto` will default to `high`.
    #[serde(rename = "detail", skip_serializing_if = "Option::is_none")]
    pub detail: Option<Detail>,
    /// Transcript of the audio (for `input_audio`). This is not sent to the model, but will be attached to the message item for reference.
    #[serde(rename = "transcript", skip_serializing_if = "Option::is_none")]
    pub transcript: Option<String>,
}

impl RealtimeConversationItemMessageUserContentInner {
    pub fn new() -> RealtimeConversationItemMessageUserContentInner {
        RealtimeConversationItemMessageUserContentInner {
            r#type: None,
            text: None,
            audio: None,
            image_url: None,
            detail: None,
            transcript: None,
        }
    }
}
/// The content type (`input_text`, `input_audio`, or `input_image`).
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Type {
    #[serde(rename = "input_text")]
    InputText,
    #[serde(rename = "input_audio")]
    InputAudio,
    #[serde(rename = "input_image")]
    InputImage,
}

impl Default for Type {
    fn default() -> Type {
        Self::InputText
    }
}
/// The detail level of the image (for `input_image`). `auto` will default to `high`.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Detail {
    #[serde(rename = "auto")]
    Auto,
    #[serde(rename = "low")]
    Low,
    #[serde(rename = "high")]
    High,
}

impl Default for Detail {
    fn default() -> Detail {
        Self::Auto
    }
}
