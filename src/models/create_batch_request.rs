/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize, bon::Builder)]
pub struct CreateBatchRequest {
    /// The ID of an uploaded file that contains requests for the new batch.  See [upload file](https://platform.openai.com/docs/api-reference/files/create) for how to upload a file.  Your input file must be formatted as a [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size. 
    #[serde(rename = "input_file_id")]
    pub input_file_id: String,
    /// The endpoint to be used for all requests in the batch. Currently `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
    #[serde(rename = "endpoint")]
    pub endpoint: Endpoint,
    /// The time frame within which the batch should be processed. Currently only `24h` is supported.
    #[serde(rename = "completion_window")]
    pub completion_window: CompletionWindow,
    /// Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.   Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters. 
    #[serde(rename = "metadata", skip_serializing_if = "Option::is_none")]
    pub metadata: Option<std::collections::HashMap<String, String>>,
    #[serde(rename = "output_expires_after", skip_serializing_if = "Option::is_none")]
    pub output_expires_after: Option<Box<models::BatchFileExpirationAfter>>,
}

impl CreateBatchRequest {
    pub fn new(input_file_id: String, endpoint: Endpoint, completion_window: CompletionWindow) -> CreateBatchRequest {
        CreateBatchRequest {
            input_file_id,
            endpoint,
            completion_window,
            metadata: None,
            output_expires_after: None,
        }
    }
}
/// The endpoint to be used for all requests in the batch. Currently `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Endpoint {
    #[serde(rename = "/v1/responses")]
    SlashV1SlashResponses,
    #[serde(rename = "/v1/chat/completions")]
    SlashV1SlashChatSlashCompletions,
    #[serde(rename = "/v1/embeddings")]
    SlashV1SlashEmbeddings,
    #[serde(rename = "/v1/completions")]
    SlashV1SlashCompletions,
}

impl Default for Endpoint {
    fn default() -> Endpoint {
        Self::SlashV1SlashResponses
    }
}
/// The time frame within which the batch should be processed. Currently only `24h` is supported.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum CompletionWindow {
    #[serde(rename = "24h")]
    Variant24h,
}

impl Default for CompletionWindow {
    fn default() -> CompletionWindow {
        Self::Variant24h
    }
}

