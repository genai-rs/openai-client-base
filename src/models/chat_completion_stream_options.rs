/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// ChatCompletionStreamOptions : Options for streaming response. Only set this when you set `stream: true`. 
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize, bon::Builder)]
pub struct ChatCompletionStreamOptions {
    /// If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array.  All other chunks will also include a `usage` field, but with a null value. **NOTE:** If the stream is interrupted, you may not receive the final usage chunk which contains the total token usage for the request. 
    #[serde(rename = "include_usage", skip_serializing_if = "Option::is_none")]
    pub include_usage: Option<bool>,
    /// When true, stream obfuscation will be enabled. Stream obfuscation adds random characters to an `obfuscation` field on streaming delta events to normalize payload sizes as a mitigation to certain side-channel attacks. These obfuscation fields are included by default, but add a small amount of overhead to the data stream. You can set `include_obfuscation` to false to optimize for bandwidth if you trust the network links between your application and the OpenAI API. 
    #[serde(rename = "include_obfuscation", skip_serializing_if = "Option::is_none")]
    pub include_obfuscation: Option<bool>,
}

impl ChatCompletionStreamOptions {
    /// Options for streaming response. Only set this when you set `stream: true`. 
    pub fn new() -> ChatCompletionStreamOptions {
        ChatCompletionStreamOptions {
            include_usage: None,
            include_obfuscation: None,
        }
    }
}

