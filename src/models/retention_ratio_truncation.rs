/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 *
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// RetentionRatioTruncation : Retain a fraction of the conversation tokens when the conversation exceeds the input token limit. This allows you to amortize truncations across multiple turns, which can help improve cached token usage.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize, bon::Builder)]
pub struct RetentionRatioTruncation {
    /// Use retention ratio truncation.
    #[serde(rename = "type")]
    pub r#type: Type,
    /// Fraction of post-instruction conversation tokens to retain (0.0 - 1.0) when the conversation exceeds the input token limit.
    #[serde(rename = "retention_ratio")]
    pub retention_ratio: f64,
}

impl RetentionRatioTruncation {
    /// Retain a fraction of the conversation tokens when the conversation exceeds the input token limit. This allows you to amortize truncations across multiple turns, which can help improve cached token usage.
    pub fn new(r#type: Type, retention_ratio: f64) -> RetentionRatioTruncation {
        RetentionRatioTruncation {
            r#type,
            retention_ratio,
        }
    }
}
/// Use retention ratio truncation.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Type {
    #[serde(rename = "retention_ratio")]
    RetentionRatio,
}

impl Default for Type {
    fn default() -> Type {
        Self::RetentionRatio
    }
}
