/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// RealtimeServerEventInputAudioBufferSpeechStopped : Returned in `server_vad` mode when the server detects the end of speech in  the audio buffer. The server will also send an `conversation.item.created`  event with the user message item that is created from the audio buffer. 
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize, bon::Builder)]
pub struct RealtimeServerEventInputAudioBufferSpeechStopped {
    /// The unique ID of the server event.
    #[serde(rename = "event_id")]
    pub event_id: String,
    #[serde(rename = "type", deserialize_with = "Option::deserialize")]
    pub r#type: Option<serde_json::Value>,
    /// Milliseconds since the session started when speech stopped. This will  correspond to the end of audio sent to the model, and thus includes the  `min_silence_duration_ms` configured in the Session. 
    #[serde(rename = "audio_end_ms")]
    pub audio_end_ms: i32,
    /// The ID of the user message item that will be created.
    #[serde(rename = "item_id")]
    pub item_id: String,
}

impl RealtimeServerEventInputAudioBufferSpeechStopped {
    /// Returned in `server_vad` mode when the server detects the end of speech in  the audio buffer. The server will also send an `conversation.item.created`  event with the user message item that is created from the audio buffer. 
    pub fn new(event_id: String, r#type: Option<serde_json::Value>, audio_end_ms: i32, item_id: String) -> RealtimeServerEventInputAudioBufferSpeechStopped {
        RealtimeServerEventInputAudioBufferSpeechStopped {
            event_id,
            r#type,
            audio_end_ms,
            item_id,
        }
    }
}

