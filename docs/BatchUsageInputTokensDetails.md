# BatchUsageInputTokensDetails

## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**cached_tokens** | **i32** | The number of tokens that were retrieved from the cache. [More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).  | 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)


